{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKJi73VEHDzdL5IpkZ/okc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adt125/AI_project_2023/blob/master/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4ls5_q_dYDI5"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('mode.chained_assignment', None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"mentalhealth.csv\")"
      ],
      "metadata": {
        "id": "8UFfjnGZYNfn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lZYa9-blYxzz",
        "outputId": "bdb35ba4-2dce-4709-f309-148440b6e187"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Question_ID                                          Questions  \\\n",
              "0      1590140        What does it mean to have a mental illness?   \n",
              "1      2110618                    Who does mental illness affect?   \n",
              "2      9434130  What are some of the warning signs of mental i...   \n",
              "3      7657263            Can people with mental illness recover?   \n",
              "4      1619387  What should I do if I know someone who appears...   \n",
              "\n",
              "                                             Answers  \n",
              "0  Mental illnesses are health conditions that di...  \n",
              "1  Mental illness does can affect anyone, regardl...  \n",
              "2  Symptoms of mental health disorders vary depen...  \n",
              "3  When healing from mental illness, early identi...  \n",
              "4  We encourage those with symptoms to talk to th...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bab2b80d-dd61-41dc-9268-f1bcdc901e69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question_ID</th>\n",
              "      <th>Questions</th>\n",
              "      <th>Answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1590140</td>\n",
              "      <td>What does it mean to have a mental illness?</td>\n",
              "      <td>Mental illnesses are health conditions that di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2110618</td>\n",
              "      <td>Who does mental illness affect?</td>\n",
              "      <td>Mental illness does can affect anyone, regardl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9434130</td>\n",
              "      <td>What are some of the warning signs of mental i...</td>\n",
              "      <td>Symptoms of mental health disorders vary depen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7657263</td>\n",
              "      <td>Can people with mental illness recover?</td>\n",
              "      <td>When healing from mental illness, early identi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1619387</td>\n",
              "      <td>What should I do if I know someone who appears...</td>\n",
              "      <td>We encourage those with symptoms to talk to th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bab2b80d-dd61-41dc-9268-f1bcdc901e69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bab2b80d-dd61-41dc-9268-f1bcdc901e69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bab2b80d-dd61-41dc-9268-f1bcdc901e69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data preprocessing \n",
        "\n",
        "for i in range(data.shape[0]):\n",
        "  data['Answers'][i]=re.sub(r'\\n', ' ',data['Answers'][i])\n",
        "  data['Answers'][i]=re.sub('\\(', '',data['Answers'][i]) \n",
        "  data['Answers'][i]=re.sub(r'\\)', '',data['Answers'][i]) \n",
        "  data['Answers'][i]=re.sub(r',', '',data['Answers'][i]) \n",
        "  data['Answers'][i]=re.sub(r'-', '',data['Answers'][i])\n",
        "  data['Answers'][i]=re.sub(r'/', '',data['Answers'][i])  \n",
        "  data['Answers'][i]=re.sub(r'/', '',data['Answers'][i])"
      ],
      "metadata": {
        "id": "yRH0XNTXYzoO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs=[]\n",
        "\n",
        "for i in range(data.shape[0]):\n",
        "  pairs.append(((data['Questions'][i]),data['Answers'][i]))\n",
        "\n",
        "# pairs"
      ],
      "metadata": {
        "id": "Lpdp2fD4ZftH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_docs = []\n",
        "target_docs = []\n",
        "input_tokens = set()\n",
        "target_tokens = set()\n",
        "\n",
        "for line in pairs:\n",
        "\n",
        "  input_doc, target_doc = line[0], line[1]\n",
        "\n",
        "  # Appending each input sentence to input_docs\n",
        "  input_docs.append(input_doc)\n",
        "\n",
        "  # Splitting words from punctuation  \n",
        "  target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
        "\n",
        "  # Redefine target_doc below and append it to target_docs\n",
        "  target_doc = ' ' + target_doc + ' '\n",
        "\n",
        "  target_docs.append(target_doc)\n",
        "\n",
        "  for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
        "    if token not in input_tokens:\n",
        "      input_tokens.add(token)\n",
        "  for token in target_doc.split():\n",
        "    if token not in target_tokens:\n",
        "      target_tokens.add(token)\n",
        "\n",
        "input_tokens = sorted(list(input_tokens))  # contains all words of input_docs\n",
        "target_tokens = sorted(list(target_tokens))\n",
        "num_encoder_tokens = len(input_tokens)\n",
        "num_decoder_tokens = len(target_tokens)"
      ],
      "metadata": {
        "id": "MdR6sjoBZtCZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_features_dict = dict([(token, i) for i, token in enumerate(input_tokens)])\n",
        "target_features_dict = dict([(token, i) for i, token in enumerate(target_tokens)])\n",
        "\n",
        "reverse_input_features_dict = dict((i, token) for token, i in input_features_dict.items())\n",
        "reverse_target_features_dict = dict((i, token) for token, i in target_features_dict.items())"
      ],
      "metadata": {
        "id": "Ix4xtBgqZyg9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder - Decoder model"
      ],
      "metadata": {
        "id": "_BG3Yw-maVVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
        "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
        "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
        "        #Assign 1. for the current line, timestep, & word in encoder_input_data\n",
        "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
        "    \n",
        "    for timestep, token in enumerate(target_doc.split()):\n",
        "        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
        "        if timestep > 0:\n",
        "            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1."
      ],
      "metadata": {
        "id": "mEM2NhxZaQZU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "funmvIuJadmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.models import Model  \n",
        "dimensionality = 256 # Dimensionality \n",
        "batch_size = 10   # The batch size and number of epochs\n",
        "epochs = 500 \n",
        "\n",
        "#Encoder\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder_lstm = LSTM(dimensionality, return_state=True)\n",
        "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_hidden, state_cell]\n",
        "\n",
        "#Decoder\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\n",
        "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "cQF-jA37aZVN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs) # Compiling\n",
        "\n",
        "training_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE7yoKi_a8r1",
        "outputId": "4cb95050-ad98-49fc-9319-b36e1460a89c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 282)]  0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 3099)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 256),        551936      ['input_1[0][0]']                \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 256),  3436544     ['input_2[0][0]',                \n",
            "                                 (None, 256),                     'lstm[0][1]',                   \n",
            "                                 (None, 256)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 3099)   796443      ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,784,923\n",
            "Trainable params: 4,784,923\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')#Training\n",
        "history1=training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)\n",
        "training_model.save('training_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyF0kUtabGPy",
        "outputId": "ccee6e7b-cf24-4bad-d9bd-d1b386bea07a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 176s 22s/step - loss: 1.2588 - accuracy: 0.1152 - val_loss: 1.4029 - val_accuracy: 0.0086\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 172s 22s/step - loss: 1.2569 - accuracy: 0.0078 - val_loss: 1.4005 - val_accuracy: 0.0093\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 177s 22s/step - loss: 1.2515 - accuracy: 0.0080 - val_loss: 1.3676 - val_accuracy: 0.0093\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 170s 21s/step - loss: 1.1773 - accuracy: 0.0080 - val_loss: 1.2471 - val_accuracy: 0.0093\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 174s 22s/step - loss: 1.1020 - accuracy: 0.0080 - val_loss: 1.2456 - val_accuracy: 0.0093\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 170s 22s/step - loss: 1.1003 - accuracy: 0.0080 - val_loss: 1.2415 - val_accuracy: 0.0093\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 167s 21s/step - loss: 1.0984 - accuracy: 0.0080 - val_loss: 1.2376 - val_accuracy: 0.0093\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 157s 20s/step - loss: 1.0980 - accuracy: 0.0080 - val_loss: 1.2214 - val_accuracy: 0.0093\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 164s 21s/step - loss: 1.0896 - accuracy: 0.0080 - val_loss: 1.2327 - val_accuracy: 0.0093\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 159s 20s/step - loss: 1.0908 - accuracy: 0.0080 - val_loss: 1.2350 - val_accuracy: 0.0093\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 160s 20s/step - loss: 1.0894 - accuracy: 0.0080 - val_loss: 1.2430 - val_accuracy: 0.0093\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 170s 22s/step - loss: 1.0973 - accuracy: 0.0080 - val_loss: 1.2122 - val_accuracy: 0.0093\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 172s 22s/step - loss: 1.0797 - accuracy: 0.0080 - val_loss: 1.2442 - val_accuracy: 0.0093\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 169s 21s/step - loss: 1.0902 - accuracy: 0.0080 - val_loss: 1.2366 - val_accuracy: 0.0093\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 167s 21s/step - loss: 1.0884 - accuracy: 0.0080 - val_loss: 1.2375 - val_accuracy: 0.0093\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 165s 21s/step - loss: 1.0904 - accuracy: 0.0080 - val_loss: 1.2217 - val_accuracy: 0.0093\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 165s 21s/step - loss: 1.0837 - accuracy: 0.0080 - val_loss: 1.2313 - val_accuracy: 0.0093\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 164s 21s/step - loss: 1.0891 - accuracy: 0.0080 - val_loss: 1.2188 - val_accuracy: 0.0093\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 165s 21s/step - loss: 1.0853 - accuracy: 0.0080 - val_loss: 1.2260 - val_accuracy: 0.0093\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 164s 21s/step - loss: 1.0822 - accuracy: 0.0080 - val_loss: 1.2438 - val_accuracy: 0.0093\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 157s 20s/step - loss: 1.0894 - accuracy: 0.0080 - val_loss: 1.2419 - val_accuracy: 0.0093\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 165s 21s/step - loss: 1.0946 - accuracy: 0.0080 - val_loss: 1.2246 - val_accuracy: 0.0093\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 171s 22s/step - loss: 1.0859 - accuracy: 0.0080 - val_loss: 1.2222 - val_accuracy: 0.0093\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 168s 21s/step - loss: 1.0832 - accuracy: 0.0080 - val_loss: 1.2338 - val_accuracy: 0.0093\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 170s 22s/step - loss: 1.0918 - accuracy: 0.0080 - val_loss: 1.2115 - val_accuracy: 0.0093\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 169s 21s/step - loss: 1.0812 - accuracy: 0.0080 - val_loss: 1.2250 - val_accuracy: 0.0093\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 170s 22s/step - loss: 1.0817 - accuracy: 0.0080 - val_loss: 1.2327 - val_accuracy: 0.0093\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 166s 21s/step - loss: 1.0901 - accuracy: 0.0080 - val_loss: 1.2253 - val_accuracy: 0.0093\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 155s 20s/step - loss: 1.0815 - accuracy: 0.0080 - val_loss: 1.2386 - val_accuracy: 0.0093\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 165s 21s/step - loss: 1.0891 - accuracy: 0.0080 - val_loss: 1.2403 - val_accuracy: 0.0093\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 164s 21s/step - loss: 1.0909 - accuracy: 0.0080 - val_loss: 1.2320 - val_accuracy: 0.0093\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 164s 21s/step - loss: 1.0862 - accuracy: 0.0080 - val_loss: 1.2376 - val_accuracy: 0.0093\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 158s 20s/step - loss: 1.0909 - accuracy: 0.0080 - val_loss: 1.2339 - val_accuracy: 0.0093\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 163s 21s/step - loss: 1.0885 - accuracy: 0.0080 - val_loss: 1.2378 - val_accuracy: 0.0093\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 166s 21s/step - loss: 1.0898 - accuracy: 0.0080 - val_loss: 1.2391 - val_accuracy: 0.0093\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 175s 22s/step - loss: 1.0899 - accuracy: 0.0080 - val_loss: 1.2341 - val_accuracy: 0.0093\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 164s 21s/step - loss: 1.0918 - accuracy: 0.0080 - val_loss: 1.2193 - val_accuracy: 0.0093\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 173s 22s/step - loss: 1.0859 - accuracy: 0.0080 - val_loss: 1.2251 - val_accuracy: 0.0093\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 172s 22s/step - loss: 1.0842 - accuracy: 0.0080 - val_loss: 1.2437 - val_accuracy: 0.0093\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 171s 22s/step - loss: 1.0931 - accuracy: 0.0080 - val_loss: 1.2295 - val_accuracy: 0.0093\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 172s 22s/step - loss: 1.0863 - accuracy: 0.0080 - val_loss: 1.2450 - val_accuracy: 0.0093\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 167s 21s/step - loss: 1.0959 - accuracy: 0.0080 - val_loss: 1.2172 - val_accuracy: 0.0093\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 166s 21s/step - loss: 1.0866 - accuracy: 0.0080 - val_loss: 1.2264 - val_accuracy: 0.0093\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 167s 21s/step - loss: 1.0851 - accuracy: 0.0080 - val_loss: 1.2397 - val_accuracy: 0.0093\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 161s 20s/step - loss: 1.0923 - accuracy: 0.0080 - val_loss: 1.2302 - val_accuracy: 0.0093\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 170s 21s/step - loss: 1.0851 - accuracy: 0.0080 - val_loss: 1.2377 - val_accuracy: 0.0093\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 172s 22s/step - loss: 1.0874 - accuracy: 0.0080 - val_loss: 1.2501 - val_accuracy: 0.0093\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 171s 22s/step - loss: 1.0913 - accuracy: 0.0080 - val_loss: 1.2339 - val_accuracy: 0.0093\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 175s 22s/step - loss: 1.0891 - accuracy: 0.0080 - val_loss: 1.2391 - val_accuracy: 0.0093\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 171s 22s/step - loss: 1.0890 - accuracy: 0.0080 - val_loss: 1.2341 - val_accuracy: 0.0093\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 175s 22s/step - loss: 1.0882 - accuracy: 0.0080 - val_loss: 1.2361 - val_accuracy: 0.0093\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 170s 22s/step - loss: 1.0910 - accuracy: 0.0080 - val_loss: 1.2262 - val_accuracy: 0.0093\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 172s 22s/step - loss: 1.0808 - accuracy: 0.0080 - val_loss: 1.2428 - val_accuracy: 0.0093\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 170s 21s/step - loss: 1.0878 - accuracy: 0.0080 - val_loss: 1.2323 - val_accuracy: 0.0093\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 169s 21s/step - loss: 1.0825 - accuracy: 0.0080 - val_loss: 1.2427 - val_accuracy: 0.0093\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 170s 21s/step - loss: 1.0878 - accuracy: 0.0080 - val_loss: 1.2361 - val_accuracy: 0.0093\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 170s 22s/step - loss: 1.0885 - accuracy: 0.0080 - val_loss: 1.2258 - val_accuracy: 0.0093\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 170s 22s/step - loss: 1.0856 - accuracy: 0.0080 - val_loss: 1.2291 - val_accuracy: 0.0093\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 171s 22s/step - loss: 1.0831 - accuracy: 0.0080 - val_loss: 1.2451 - val_accuracy: 0.0093\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 163s 21s/step - loss: 1.0924 - accuracy: 0.0080 - val_loss: 1.2258 - val_accuracy: 0.0093\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 172s 22s/step - loss: 1.0870 - accuracy: 0.0080 - val_loss: 1.2259 - val_accuracy: 0.0093\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 174s 22s/step - loss: 1.0854 - accuracy: 0.0080 - val_loss: 1.2297 - val_accuracy: 0.0093\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 172s 22s/step - loss: 1.0879 - accuracy: 0.0080 - val_loss: 1.2307 - val_accuracy: 0.0093\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 176s 22s/step - loss: 1.0874 - accuracy: 0.0081 - val_loss: 1.2354 - val_accuracy: 0.0093\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 174s 22s/step - loss: 1.0930 - accuracy: 0.0081 - val_loss: 1.2152 - val_accuracy: 0.0093\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 174s 22s/step - loss: 1.0831 - accuracy: 0.0081 - val_loss: 1.2354 - val_accuracy: 0.0093\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 179s 23s/step - loss: 1.0907 - accuracy: 0.0081 - val_loss: 1.2281 - val_accuracy: 0.0093\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 173s 22s/step - loss: 1.0887 - accuracy: 0.0081 - val_loss: 1.2231 - val_accuracy: 0.0093\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 175s 22s/step - loss: 1.0861 - accuracy: 0.0081 - val_loss: 1.2340 - val_accuracy: 0.0093\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 170s 22s/step - loss: 1.0881 - accuracy: 0.0081 - val_loss: 1.2275 - val_accuracy: 0.0093\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 168s 21s/step - loss: 1.0860 - accuracy: 0.0081 - val_loss: 1.2267 - val_accuracy: 0.0093\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 168s 21s/step - loss: 1.0848 - accuracy: 0.0081 - val_loss: 1.2355 - val_accuracy: 0.0093\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 174s 22s/step - loss: 1.0916 - accuracy: 0.0081 - val_loss: 1.2211 - val_accuracy: 0.0093\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 172s 22s/step - loss: 1.0863 - accuracy: 0.0081 - val_loss: 1.2257 - val_accuracy: 0.0093\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 172s 22s/step - loss: 1.0857 - accuracy: 0.0081 - val_loss: 1.2307 - val_accuracy: 0.0093\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 174s 22s/step - loss: 1.0858 - accuracy: 0.0081 - val_loss: 1.2421 - val_accuracy: 0.0093\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 174s 22s/step - loss: 1.0912 - accuracy: 0.0081 - val_loss: 1.2198 - val_accuracy: 0.0093\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 177s 23s/step - loss: 1.0811 - accuracy: 0.0082 - val_loss: 1.2294 - val_accuracy: 0.0094\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 172s 22s/step - loss: 1.0846 - accuracy: 0.0082 - val_loss: 1.2301 - val_accuracy: 0.0093\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 165s 21s/step - loss: 1.0861 - accuracy: 0.0082 - val_loss: 1.2282 - val_accuracy: 0.0094\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 163s 20s/step - loss: 1.0816 - accuracy: 0.0082 - val_loss: 1.2390 - val_accuracy: 0.0094\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 170s 22s/step - loss: 1.0895 - accuracy: 0.0082 - val_loss: 1.2259 - val_accuracy: 0.0095\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 173s 22s/step - loss: 1.0838 - accuracy: 0.0082 - val_loss: 1.2382 - val_accuracy: 0.0094\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 174s 22s/step - loss: 1.0887 - accuracy: 0.0082 - val_loss: 1.2431 - val_accuracy: 0.0095\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 177s 23s/step - loss: 1.0913 - accuracy: 0.0082 - val_loss: 1.2378 - val_accuracy: 0.0094\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 177s 23s/step - loss: 1.0889 - accuracy: 0.0082 - val_loss: 1.2329 - val_accuracy: 0.0095\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 179s 23s/step - loss: 1.0858 - accuracy: 0.0082 - val_loss: 1.2421 - val_accuracy: 0.0095\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 184s 23s/step - loss: 1.0901 - accuracy: 0.0082 - val_loss: 1.2282 - val_accuracy: 0.0095\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 178s 22s/step - loss: 1.0886 - accuracy: 0.0082 - val_loss: 1.2355 - val_accuracy: 0.0095\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 180s 23s/step - loss: 1.0901 - accuracy: 0.0082 - val_loss: 1.2269 - val_accuracy: 0.0095\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 175s 22s/step - loss: 1.0844 - accuracy: 0.0082 - val_loss: 1.2355 - val_accuracy: 0.0095\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 165s 21s/step - loss: 1.0909 - accuracy: 0.0082 - val_loss: 1.2330 - val_accuracy: 0.0095\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 171s 22s/step - loss: 1.0843 - accuracy: 0.0082 - val_loss: 1.2328 - val_accuracy: 0.0095\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 165s 21s/step - loss: 1.0852 - accuracy: 0.0082 - val_loss: 1.2354 - val_accuracy: 0.0095\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 172s 22s/step - loss: 1.0825 - accuracy: 0.0082 - val_loss: 1.2404 - val_accuracy: 0.0095\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 173s 22s/step - loss: 1.0924 - accuracy: 0.0082 - val_loss: 1.2303 - val_accuracy: 0.0095\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 174s 22s/step - loss: 1.0877 - accuracy: 0.0082 - val_loss: 1.2211 - val_accuracy: 0.0095\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 174s 22s/step - loss: 1.0828 - accuracy: 0.0082 - val_loss: 1.2343 - val_accuracy: 0.0095\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 175s 22s/step - loss: 1.0912 - accuracy: 0.0082 - val_loss: 1.2173 - val_accuracy: 0.0095\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 173s 22s/step - loss: 1.0830 - accuracy: 0.0082 - val_loss: 1.2243 - val_accuracy: 0.0095\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 172s 22s/step - loss: 1.0839 - accuracy: 0.0082 - val_loss: 1.2303 - val_accuracy: 0.0095\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 171s 22s/step - loss: 1.0882 - accuracy: 0.0082 - val_loss: 1.2305 - val_accuracy: 0.0095\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 175s 22s/step - loss: 1.0835 - accuracy: 0.0082 - val_loss: 1.2372 - val_accuracy: 0.0095\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 168s 21s/step - loss: 1.0824 - accuracy: 0.0082 - val_loss: 1.2439 - val_accuracy: 0.0095\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 169s 21s/step - loss: 1.0892 - accuracy: 0.0082 - val_loss: 1.2360 - val_accuracy: 0.0095\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 169s 21s/step - loss: 1.0862 - accuracy: 0.0082 - val_loss: 1.2315 - val_accuracy: 0.0095\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 169s 21s/step - loss: 1.0854 - accuracy: 0.0082 - val_loss: 1.2366 - val_accuracy: 0.0095\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 170s 21s/step - loss: 1.0876 - accuracy: 0.0082 - val_loss: 1.2335 - val_accuracy: 0.0095\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 180s 23s/step - loss: 1.0849 - accuracy: 0.0082 - val_loss: 1.2447 - val_accuracy: 0.0095\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 176s 22s/step - loss: 1.0927 - accuracy: 0.0082 - val_loss: 1.2194 - val_accuracy: 0.0095\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 178s 23s/step - loss: 1.0845 - accuracy: 0.0082 - val_loss: 1.2245 - val_accuracy: 0.0095\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 170s 22s/step - loss: 1.0783 - accuracy: 0.0082 - val_loss: 1.2452 - val_accuracy: 0.0095\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 167s 21s/step - loss: 1.0849 - accuracy: 0.0082 - val_loss: 1.2519 - val_accuracy: 0.0095\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 173s 22s/step - loss: 1.0957 - accuracy: 0.0082 - val_loss: 1.2228 - val_accuracy: 0.0095\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 173s 22s/step - loss: 1.0868 - accuracy: 0.0082 - val_loss: 1.2143 - val_accuracy: 0.0095\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 173s 22s/step - loss: 1.0811 - accuracy: 0.0082 - val_loss: 1.2135 - val_accuracy: 0.0094\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 168s 21s/step - loss: 1.0753 - accuracy: 0.0082 - val_loss: 1.2391 - val_accuracy: 0.0094\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 170s 22s/step - loss: 1.0875 - accuracy: 0.0082 - val_loss: 1.2301 - val_accuracy: 0.0094\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 170s 21s/step - loss: 1.0868 - accuracy: 0.0082 - val_loss: 1.2259 - val_accuracy: 0.0094\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 170s 22s/step - loss: 1.0822 - accuracy: 0.0082 - val_loss: 1.2359 - val_accuracy: 0.0095\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 171s 22s/step - loss: 1.0856 - accuracy: 0.0082 - val_loss: 1.2338 - val_accuracy: 0.0095\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 174s 22s/step - loss: 1.0871 - accuracy: 0.0082 - val_loss: 1.2370 - val_accuracy: 0.0094\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 173s 22s/step - loss: 1.0839 - accuracy: 0.0082 - val_loss: 1.2390 - val_accuracy: 0.0095\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 173s 22s/step - loss: 1.0872 - accuracy: 0.0082 - val_loss: 1.2380 - val_accuracy: 0.0095\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 168s 21s/step - loss: 1.0879 - accuracy: 0.0082 - val_loss: 1.2290 - val_accuracy: 0.0095\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 168s 21s/step - loss: 1.0867 - accuracy: 0.0082 - val_loss: 1.2254 - val_accuracy: 0.0095\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 173s 22s/step - loss: 1.0820 - accuracy: 0.0082 - val_loss: 1.2380 - val_accuracy: 0.0094\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 171s 22s/step - loss: 1.0886 - accuracy: 0.0082 - val_loss: 1.2281 - val_accuracy: 0.0095\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 167s 21s/step - loss: 1.0830 - accuracy: 0.0082 - val_loss: 1.2438 - val_accuracy: 0.0094\n",
            "Epoch 130/500\n",
            "4/8 [==============>...............] - ETA: 1:20 - loss: 1.2155 - accuracy: 0.0090"
          ]
        }
      ]
    }
  ]
}